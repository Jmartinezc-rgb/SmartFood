{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import re\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Lista (o set) de ingredientes objetivo (coincidencia en minúsculas)\n",
    "TARGET_INGREDIENTS = {\n",
    "    \"bacon\", \"garden cress-chamsur ko saag-\", \"green lentils\", \"chicken gizzards\",\n",
    "    \"red beans\", \"pumpkin -farsi-\", \"sajjyun -moringa drumsticks-\", \"chickpeas\",\n",
    "    \"green brinjal\", \"buff meat\", \"ham\", \"butter\", \"mutton\", \"papaya\", \"paneer\",\n",
    "    \"broccoli\", \"mayonnaise\", \"rahar ko daal\", \"soyabean -bhatmas-\", \"kimchi\",\n",
    "    \"beaten rice -chiura-\", \"bethu ko saag\", \"sugar\", \"ketchup\", \"thukpa noodles\",\n",
    "    \"cauliflower\", \"sausage\", \"cornflakec\", \"noodle\", \"chowmein noodles\", \"salt\",\n",
    "    \"chili powder\", \"palak -indian spinach-\", \"moringa leaves -sajyun ko munta-\",\n",
    "    \"soy sauce\", \"milk\", \"green soyabean -hariyo bhatmas-\", \"tori ko saag\",\n",
    "    \"chicken\", \"beef\", \"olive oil\", \"seaweed\", \"tofu\", \"black beans\", \"minced meat\",\n",
    "    \"green peas\", \"crab meat\", \"strawberry\", \"ginger\", \"ice\", \"water melon\",\n",
    "    \"wallnut\", \"long beans -bodi-\", \"yellow lentils\", \"pea\", \"orange\", \"fish\",\n",
    "    \"apple\", \"pear\", \"wheat\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_recipe_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpia el nombre de la receta para que sea más legible.\n",
    "    - Convierte a minúsculas\n",
    "    - Elimina contenido entre paréntesis ( ... )\n",
    "    - Elimina contenido entre corchetes [ ... ] (por si existe)\n",
    "    - Elimina caracteres no deseados, dejando letras, dígitos, espacios y guiones\n",
    "    - Elimina espacios repetidos\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    # Eliminar contenido entre paréntesis\n",
    "    name = re.sub(r\"\\([^)]*\\)\", \"\", name)\n",
    "    # Eliminar contenido entre corchetes\n",
    "    name = re.sub(r\"\\[[^]]*\\]\", \"\", name)\n",
    "    # Mantener solo letras, dígitos, espacios y guiones\n",
    "    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n",
    "    # Remover espacios repetidos\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def has_target_ingredient(ing_list):\n",
    "    \"\"\"\n",
    "    Retorna True si la receta contiene al menos uno de los ingredientes objetivo,\n",
    "    comparando en minúsculas.\n",
    "    \"\"\"\n",
    "    ing_list_lower = [i.strip().lower() for i in ing_list]\n",
    "    return any(ing in TARGET_INGREDIENTS for ing in ing_list_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas en RAW_recipes: 231637\n",
      "Recetas tras filtrar por ingredientes objetivo: 174209\n",
      "Recetas seleccionadas: 20000\n",
      "Nuevo CSV guardado: new_recipes_20000.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. Cargar el CSV RAW_recipes.csv\n",
    "    df = pd.read_csv(\"foodcom_data/RAW_recipes.csv\")\n",
    "    print(\"Total de filas en RAW_recipes:\", len(df))\n",
    "\n",
    "    # 2. Eliminar filas sin 'name', 'ingredients' o 'nutrition'\n",
    "    df = df.dropna(subset=[\"name\", \"ingredients\", \"nutrition\"])\n",
    "\n",
    "    # 3. Convertir la columna 'ingredients' a lista Python\n",
    "    df[\"ingredient_list\"] = df[\"ingredients\"].apply(ast.literal_eval)\n",
    "\n",
    "    # 4. Filtrar recetas que contengan al menos uno de los ingredientes objetivo\n",
    "    df_filtered = df[df[\"ingredient_list\"].apply(has_target_ingredient)]\n",
    "    print(\"Recetas tras filtrar por ingredientes objetivo:\", len(df_filtered))\n",
    "\n",
    "    # 5. Seleccionar aleatoriamente 20,000 recetas (o menos si hay menos disponibles)\n",
    "    n_muestras = min(len(df_filtered), 20000)\n",
    "    df_sample = df_filtered.sample(n=n_muestras, random_state=42)\n",
    "    print(\"Recetas seleccionadas:\", len(df_sample))\n",
    "\n",
    "    # 6. Convertir la columna 'nutrition' a lista de valores\n",
    "    df_sample[\"nutrition_list\"] = df_sample[\"nutrition\"].apply(ast.literal_eval)\n",
    "\n",
    "    # 7. Separar la lista nutricional en 7 columnas\n",
    "    nutri_cols = [\n",
    "        \"calories\",\n",
    "        \"total_fat_pdv\",\n",
    "        \"sugar_pdv\",\n",
    "        \"sodium_pdv\",\n",
    "        \"protein_pdv\",\n",
    "        \"saturated_fat_pdv\",\n",
    "        \"carbs_pdv\"\n",
    "    ]\n",
    "    nutrition_df = pd.DataFrame(df_sample[\"nutrition_list\"].tolist(), index=df_sample.index)\n",
    "    nutrition_df.columns = nutri_cols\n",
    "\n",
    "    # 8. Crear DataFrame final con name + columnas nutricionales\n",
    "    #    y limpiar el nombre de la receta.\n",
    "    df_sample[\"clean_name\"] = df_sample[\"name\"].apply(clean_recipe_name)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    df_final = pd.concat([df_sample[\"clean_name\"], nutrition_df], axis=1).reset_index(drop=True)\n",
    "\n",
    "    # 9. Generar IDs nuevos del 1 al número de recetas\n",
    "    df_final.index = df_final.index + 1\n",
    "    df_final.insert(0, \"id\", df_final.index)\n",
    "\n",
    "    # 10. Guardar el nuevo CSV\n",
    "    df_final.to_csv(\"new_recipes_20000.csv\", index=False)\n",
    "    print(\"Nuevo CSV guardado: new_recipes_20000.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script para generar un CSV de tripletas (ternas) a partir de dos fuentes:\n",
    "1. new_recipes_20000.csv: contiene, para cada receta (con un ID nuevo y un nombre normalizado),\n",
    "   los valores nutricionales separados en 7 columnas.\n",
    "2. RAW_recipes.csv: contiene la columna \"ingredients\" (en forma de cadena de lista).\n",
    "\n",
    "Para cada receta, el script genera:\n",
    "  - Una tripleta \"has_ingredient\" por cada ingrediente presente.\n",
    "  - Una tripleta para cada campo nutricional, usando las siguientes reglas de clasificación:\n",
    "  \n",
    "    - calories:      low_calories (<174), normal_calories (174–520), high_calories (>520)\n",
    "    - total_fat_pdv: low_fat (<8), normal_fat (8–41), high_fat (>41)\n",
    "    - sugar_pdv:     low_sugar (<9), normal_sugar (9–68), high_sugar (>68)\n",
    "    - sodium_pdv:    low_sodium (<5), normal_sodium (5–33), high_sodium (>33)\n",
    "    - protein_pdv:   low_protein (<7), normal_protein (7–51), high_protein (>51)\n",
    "    - saturated_fat_pdv: low_saturated_fat (<7), normal_saturated_fat (7–52), high_saturated_fat (>52)\n",
    "    - carbs_pdv:     low_carbs (<4), normal_carbs (4–16), high_carbs (>16)\n",
    "\n",
    "El CSV resultante (new_triplets20.csv) tendrá las columnas:\n",
    "    subject, relation, object\n",
    "\n",
    "Los \"subject\" serán el nombre normalizado de la receta (generado a partir de \"name\").\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Función para limpiar/normalizar el nombre de la receta ---\n",
    "def clean_recipe_name(name: str) -> str:\n",
    "    # Convertir a minúsculas\n",
    "    name = name.lower()\n",
    "    # Eliminar contenido entre paréntesis y corchetes\n",
    "    name = re.sub(r\"\\([^)]*\\)\", \"\", name)\n",
    "    name = re.sub(r\"\\[[^]]*\\]\", \"\", name)\n",
    "    # Mantener solo letras, dígitos, espacios y guiones\n",
    "    name = re.sub(r\"[^a-z0-9\\s-]\", \"\", name)\n",
    "    # Reducir espacios y hacer strip\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Función para clasificar valores nutricionales ---\n",
    "def classify_value(value, thresholds, low_label, normal_label, high_label):\n",
    "    \"\"\"\n",
    "    thresholds: tuple (low_threshold, high_threshold)\n",
    "      - Si value < low_threshold -> low_label\n",
    "      - Si low_threshold <= value <= high_threshold -> normal_label\n",
    "      - Si value > high_threshold -> high_label\n",
    "    \"\"\"\n",
    "    low_th, high_th = thresholds\n",
    "    if value < low_th:\n",
    "        return low_label, value\n",
    "    elif value <= high_th:\n",
    "        return normal_label, value\n",
    "    else:\n",
    "        return high_label, value\n",
    "\n",
    "# --- Definir reglas nutricionales ---\n",
    "nutri_rules = {\n",
    "    'calories': ((174, 520), \"low_calories\", \"normal_calories\", \"high_calories\"),\n",
    "    'total_fat_pdv': ((8, 41), \"low_fat\", \"normal_fat\", \"high_fat\"),\n",
    "    'sugar_pdv': ((9, 68), \"low_sugar\", \"normal_sugar\", \"high_sugar\"),\n",
    "    'sodium_pdv': ((5, 33), \"low_sodium\", \"normal_sodium\", \"high_sodium\"),\n",
    "    'protein_pdv': ((7, 51), \"low_protein\", \"normal_protein\", \"high_protein\"),\n",
    "    'saturated_fat_pdv': ((7, 52), \"low_saturated_fat\", \"normal_saturated_fat\", \"high_saturated_fat\"),\n",
    "    'carbs_pdv': ((4, 16), \"low_carbs\", \"normal_carbs\", \"high_carbs\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recetas en merge (con ingredientes): 19982\n",
      "Nuevo CSV de tripletas generado: new_triplets20.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # --- Parte A: Procesar new_recipes_20000.csv para la información nutricional ---\n",
    "    # Cargar el CSV que contiene el nombre normalizado y valores nutricionales\n",
    "    df_new = pd.read_csv(\"new_recipes_20000.csv\")\n",
    "    # Se asume que este CSV tiene las columnas:\n",
    "    #   id, clean_name, calories, total_fat_pdv, sugar_pdv, sodium_pdv, protein_pdv, saturated_fat_pdv, carbs_pdv\n",
    "    # (Si la columna con el nombre normalizado se llama de otra forma, ajústala.)\n",
    "    \n",
    "    # --- Parte B: Procesar RAW_recipes.csv para obtener los ingredientes ---\n",
    "    df_raw = pd.read_csv(\"foodcom_data/RAW_recipes.csv\")\n",
    "    df_raw = df_raw.dropna(subset=[\"name\", \"ingredients\"])\n",
    "    df_raw[\"ingredient_list\"] = df_raw[\"ingredients\"].apply(ast.literal_eval)\n",
    "    df_raw[\"clean_name\"] = df_raw[\"name\"].apply(clean_recipe_name)\n",
    "    \n",
    "    # --- Unir la información: mantener solo recetas de df_new que aparezcan en RAW_recipes ---\n",
    "    # Se hace un merge por 'clean_name'\n",
    "    df_merge = pd.merge(df_new, df_raw[[\"clean_name\", \"ingredient_list\"]], on=\"clean_name\", how=\"inner\")\n",
    "    # En caso de duplicados, se elimina para tener una única receta por clean_name\n",
    "    df_merge = df_merge.drop_duplicates(subset=[\"clean_name\"])\n",
    "    \n",
    "    print(\"Recetas en merge (con ingredientes):\", len(df_merge))\n",
    "    \n",
    "    # --- Generar Tripletas ---\n",
    "    triples = []\n",
    "\n",
    "    # 1. Tripletas para \"has_ingredient\"\n",
    "    # Por cada receta, cada ingrediente de la lista se genera como una triple\n",
    "    for _, row in df_merge.iterrows():\n",
    "        recipe = row[\"clean_name\"]  # Usamos el nombre normalizado como subject\n",
    "        for ing in row[\"ingredient_list\"]:\n",
    "            if isinstance(ing, str):\n",
    "                ingredient = ing.strip().lower()\n",
    "                triples.append([recipe, \"has_ingredient\", ingredient])\n",
    "    \n",
    "    # 2. Tripletas para las relaciones nutricionales\n",
    "    # Se generan a partir de las columnas nutricionales del CSV new_recipes_20000.csv (df_new)\n",
    "    # Nota: Usamos df_new (no el merge) para asegurar que usamos toda la información nutricional\n",
    "    for _, row in df_new.iterrows():\n",
    "        recipe = row[\"clean_name\"]\n",
    "        for col, rule in nutri_rules.items():\n",
    "            thresholds, low_label, normal_label, high_label = rule\n",
    "            try:\n",
    "                value = float(row[col])\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "            relation_label, val = classify_value(value, thresholds, low_label, normal_label, high_label)\n",
    "            triples.append([recipe, relation_label, str(val)])\n",
    "    \n",
    "    # --- Guardar las tripletas en un nuevo CSV ---\n",
    "    df_triples = pd.DataFrame(triples, columns=[\"subject\", \"relation\", \"object\"])\n",
    "    df_triples.to_csv(\"new_triplets20.csv\", index=False)\n",
    "    print(\"Nuevo CSV de tripletas generado: new_triplets20.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recetas en merge (con ingredientes): 19982\n",
      "Nuevo CSV de tripletas generado: new_triplets20.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Definir reglas nutricionales ---\n",
    "nutri_rules = {\n",
    "    'calories': ((174, 520), \"low_calories\", \"normal_calories\", \"high_calories\"),\n",
    "    'total_fat_pdv': ((8, 41), \"low_fat\", \"normal_fat\", \"high_fat\"),\n",
    "    'sugar_pdv': ((9, 68), \"low_sugar\", \"normal_sugar\", \"high_sugar\"),\n",
    "    'sodium_pdv': ((5, 33), \"low_sodium\", \"normal_sodium\", \"high_sodium\"),\n",
    "    'protein_pdv': ((7, 51), \"low_protein\", \"normal_protein\", \"high_protein\"),\n",
    "    'saturated_fat_pdv': ((7, 52), \"low_saturated_fat\", \"normal_saturated_fat\", \"high_saturated_fat\"),\n",
    "    'carbs_pdv': ((4, 16), \"low_carbs\", \"normal_carbs\", \"high_carbs\")\n",
    "}\n",
    "\n",
    "def main():\n",
    "    # --- Parte A: Procesar new_recipes_20000.csv para la información nutricional ---\n",
    "    # Cargar el CSV que contiene el nombre normalizado y valores nutricionales\n",
    "    df_new = pd.read_csv(\"new_recipes_20000.csv\")\n",
    "    # Se asume que este CSV tiene las columnas:\n",
    "    #   id, clean_name, calories, total_fat_pdv, sugar_pdv, sodium_pdv, protein_pdv, saturated_fat_pdv, carbs_pdv\n",
    "    # (Si la columna con el nombre normalizado se llama de otra forma, ajústala.)\n",
    "    \n",
    "    # --- Parte B: Procesar RAW_recipes.csv para obtener los ingredientes ---\n",
    "    df_raw = pd.read_csv(\"foodcom_data/RAW_recipes.csv\")\n",
    "    df_raw = df_raw.dropna(subset=[\"name\", \"ingredients\"])\n",
    "    df_raw[\"ingredient_list\"] = df_raw[\"ingredients\"].apply(ast.literal_eval)\n",
    "    df_raw[\"clean_name\"] = df_raw[\"name\"].apply(clean_recipe_name)\n",
    "    \n",
    "    # --- Unir la información: mantener solo recetas de df_new que aparezcan en RAW_recipes ---\n",
    "    # Se hace un merge por 'clean_name'\n",
    "    df_merge = pd.merge(df_new, df_raw[[\"clean_name\", \"ingredient_list\"]], on=\"clean_name\", how=\"inner\")\n",
    "    # En caso de duplicados, se elimina para tener una única receta por clean_name\n",
    "    df_merge = df_merge.drop_duplicates(subset=[\"clean_name\"])\n",
    "    \n",
    "    print(\"Recetas en merge (con ingredientes):\", len(df_merge))\n",
    "    \n",
    "    # --- Generar Tripletas ---\n",
    "    triples = []\n",
    "\n",
    "    # 1. Tripletas para \"has_ingredient\"\n",
    "    # Por cada receta, cada ingrediente de la lista se genera como una triple\n",
    "    for _, row in df_merge.iterrows():\n",
    "        recipe = row[\"clean_name\"]  # Usamos el nombre normalizado como subject\n",
    "        for ing in row[\"ingredient_list\"]:\n",
    "            if isinstance(ing, str):\n",
    "                ingredient = ing.strip().lower()\n",
    "                triples.append([recipe, \"has_ingredient\", ingredient])\n",
    "    \n",
    "    # 2. Tripletas para las relaciones nutricionales\n",
    "    # Se generan a partir de las columnas nutricionales del CSV new_recipes_20000.csv (df_new)\n",
    "    # Nota: Usamos df_new (no el merge) para asegurar que usamos toda la información nutricional\n",
    "    for _, row in df_new.iterrows():\n",
    "        recipe = row[\"clean_name\"]\n",
    "        for col, rule in nutri_rules.items():\n",
    "            thresholds, low_label, normal_label, high_label = rule\n",
    "            try:\n",
    "                value = float(row[col])\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "            relation_label, val = classify_value(value, thresholds, low_label, normal_label, high_label)\n",
    "            triples.append([recipe, relation_label, str(val)])\n",
    "    \n",
    "    # --- Guardar las tripletas en un nuevo CSV ---\n",
    "    df_triples = pd.DataFrame(triples, columns=[\"subject\", \"relation\", \"object\"])\n",
    "    df_triples.to_csv(\"new_triplets20.csv\", index=False)\n",
    "    print(\"Nuevo CSV de tripletas generado: new_triplets20.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ampligraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
